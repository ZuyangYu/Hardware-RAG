# src/core/hybrid_retriever.py
from typing import List, Optional, Dict
import jieba
from rank_bm25 import BM25Okapi
from llama_index.core import VectorStoreIndex, Settings
from llama_index.core.schema import NodeWithScore, QueryBundle
from llama_index.vector_stores.chroma import ChromaVectorStore
from config.settings import VECTOR_TOP_K, BM25_TOP_K, RRF_K, FINAL_TOP_K
from src.core.bm25_cache import BM25Cache
from src.core.logger import log, warn, error

_bm25_node_map: Dict[str, List[str]] = {}


def build_bm25_index(kb_name: str, index: VectorStoreIndex, force_rebuild: bool = False) -> Optional[BM25Okapi]:
    """æ„å»ºæˆ–è·å– BM25 ç´¢å¼•"""
    cache = BM25Cache()

    vector_store = index._vector_store
    if not isinstance(vector_store, ChromaVectorStore):
        warn("BM25 ä»…æ”¯æŒ ChromaVectorStore")
        return None

    collection = vector_store._collection
    current_doc_count = collection.count()

    # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
    if not force_rebuild:
        bm25 = cache.get(kb_name)
        cached_node_map = _bm25_node_map.get(kb_name, [])

        if bm25 is not None and len(cached_node_map) == current_doc_count:
            log(f"âœ… ä½¿ç”¨ç¼“å­˜çš„ BM25 ç´¢å¼•: {kb_name} ({current_doc_count} ä¸ªæ–‡æ¡£)")
            return bm25
        else:
            if bm25 is not None:
                log(f"âš ï¸ BM25 ç¼“å­˜è¿‡æœŸï¼Œé‡å»ºç´¢å¼•")

    try:
        # è·å–æ‰€æœ‰æ–‡æ¡£
        results = collection.get(include=["documents", "metadatas"])
        documents = results["documents"]
        ids = results["ids"]

        if not documents:
            log(f"âš ï¸ çŸ¥è¯†åº“ä¸ºç©ºï¼Œè·³è¿‡ BM25 ç´¢å¼•æ„å»º: {kb_name}")
            return None

        log(f"ğŸ”¨ æ„å»º BM25 ç´¢å¼•: {kb_name} ({len(documents)} ä¸ªæ–‡æ¡£)")

        # ========================================================
        # [æ ¸å¿ƒä¿®å¤] ä½¿ç”¨ Jieba åˆ†è¯ï¼Œè€Œä¸æ˜¯ split()
        corpus = [jieba.lcut(doc) for doc in documents]
        # ========================================================

        bm25 = BM25Okapi(corpus)

        # æ›´æ–°æ˜ å°„å…³ç³»
        _bm25_node_map[kb_name] = ids

        # æŒä¹…åŒ–ç¼“å­˜
        if cache.set(kb_name, bm25):
            log(f"âœ… BM25 ç´¢å¼•æ„å»ºå¹¶ç¼“å­˜æˆåŠŸ")
        else:
            warn(f"âš ï¸ BM25 ç´¢å¼•æ„å»ºæˆåŠŸä½†ç¼“å­˜å¤±è´¥")

        return bm25

    except Exception as e:
        error(f"âŒ æ„å»º BM25 ç´¢å¼•å¤±è´¥: {kb_name} - {e}")
        import traceback
        traceback.print_exc()
        return None


def hybrid_retrieve(
        query: str,
        index: VectorStoreIndex,
        kb_name: str,
        top_k: int = 20,
        vector_weight: float = 0.5,
        bm25_weight: float = 0.5
) -> List[NodeWithScore]:
    """æ··åˆæ£€ç´¢ï¼šå‘é‡æ£€ç´¢ + BM25 + RRF èåˆ + Reranker"""

    # 1. å‘é‡æ£€ç´¢
    log(f"ğŸ” å‘é‡æ£€ç´¢: {query[:50]}...")
    vector_retriever = index.as_retriever(similarity_top_k=VECTOR_TOP_K)
    vector_nodes = vector_retriever.retrieve(query)
    log(f"   â””â”€ å‘é‡æ£€ç´¢è¿”å›: {len(vector_nodes)} ä¸ªç»“æœ")

    # 2. BM25 æ£€ç´¢
    log(f"ğŸ” BM25 æ£€ç´¢: {query[:50]}...")
    bm25_nodes = []
    # å°è¯•è·å–æˆ–æ„å»ºç´¢å¼•
    bm25 = build_bm25_index(kb_name, index)
    node_ids_map = _bm25_node_map.get(kb_name, [])

    if bm25 is not None and node_ids_map:
        try:
            # æ£€ç´¢è¯ä¹Ÿå¿…é¡»ç”¨ Jieba åˆ†è¯
            query_tokens = jieba.lcut(query)
            bm25_scores = bm25.get_scores(query_tokens)

            # è·å–åˆ†æ•°æœ€é«˜çš„ Top K
            top_indices = sorted(
                range(len(bm25_scores)),
                key=lambda i: bm25_scores[i],
                reverse=True
            )[:BM25_TOP_K]

            for i in top_indices:
                if i >= len(node_ids_map):
                    continue

                node_id = node_ids_map[i]
                score = float(bm25_scores[i])

                # è¿‡æ»¤æ‰åˆ†æ•°æä½çš„ç»“æœ (å™ªéŸ³)
                if score <= 0.0:
                    continue

                try:
                    node = index.docstore.get_node(node_id)
                    bm25_nodes.append(NodeWithScore(node=node, score=score))
                except Exception:
                    continue

            log(f"   â””â”€ BM25 æ£€ç´¢è¿”å›: {len(bm25_nodes)} ä¸ªç»“æœ")
        except Exception as e:
            error(f"âŒ BM25 æ£€ç´¢è®¡ç®—å¤±è´¥: {e}")

    # 3. RRF èåˆ
    if bm25_nodes:
        log(f"ğŸ”€ RRF èåˆ: å‘é‡({len(vector_nodes)}) + BM25({len(bm25_nodes)})")
        fused_nodes = rrf_fusion(
            vector_nodes,
            bm25_nodes,
            top_k,
            vector_weight=vector_weight,
            bm25_weight=bm25_weight
        )
        log(f"   â””â”€ èåˆåè¿”å›: {len(fused_nodes)} ä¸ªç»“æœ")
    else:
        log("âš ï¸ ä»…ä½¿ç”¨å‘é‡æ£€ç´¢ç»“æœ (BM25 æœªè¿”å›æˆ–å¤±è´¥)")
        fused_nodes = vector_nodes[:top_k]

    # 4. Reranker é‡æ’åº
    if Settings.node_postprocessors:
        log("ğŸ¯ æ‰§è¡Œ Reranker é‡æ’åº...")
        query_bundle = QueryBundle(query_str=query)
        reranked_nodes = fused_nodes

        for processor in Settings.node_postprocessors:
            try:
                reranked_nodes = processor.postprocess_nodes(
                    reranked_nodes,
                    query_bundle=query_bundle
                )
            except Exception as e:
                error(f"âŒ Reranker æ‰§è¡Œå¤±è´¥: {e}")

        log(f"   â””â”€ Reranker åä¿ç•™: {len(reranked_nodes)} ä¸ªç»“æœ")
        return reranked_nodes

    return fused_nodes[:FINAL_TOP_K]


def rrf_fusion(
        vector_nodes: List[NodeWithScore],
        bm25_nodes: List[NodeWithScore],
        top_k: int,
        k: int = RRF_K,
        vector_weight: float = 0.5,
        bm25_weight: float = 0.5
) -> List[NodeWithScore]:
    """RRF (Reciprocal Rank Fusion) èåˆç®—æ³•"""
    scores = {}
    node_map = {}

    for rank, node in enumerate(vector_nodes, 1):
        node_id = node.node.node_id
        # åŠ æƒ RRF
        scores[node_id] = vector_weight / (k + rank)
        node_map[node_id] = node

    for rank, node in enumerate(bm25_nodes, 1):
        node_id = node.node.node_id
        if node_id in scores:
            scores[node_id] += bm25_weight / (k + rank)
        else:
            scores[node_id] = bm25_weight / (k + rank)
            node_map[node_id] = node

    sorted_ids = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)[:top_k]

    result = []
    for node_id in sorted_ids:
        node = node_map[node_id]
        result.append(NodeWithScore(node=node.node, score=scores[node_id]))

    return result


def invalidate_bm25_cache(kb_name: str) -> bool:
    """ä½¿ BM25 ç¼“å­˜å¤±æ•ˆ"""
    cache = BM25Cache()
    success = cache.delete(kb_name)

    if kb_name in _bm25_node_map:
        del _bm25_node_map[kb_name]

    if success:
        log(f"âœ… å·²æ¸…é™¤ BM25 ç¼“å­˜: {kb_name}")
    else:
        error(f"âŒ æ¸…é™¤ BM25 ç¼“å­˜å¤±è´¥: {kb_name}")

    return success
