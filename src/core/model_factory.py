# src/core/model_factory.py
"""
æ¨¡å‹å·¥å‚ - ç»Ÿä¸€çš„æ¨¡å‹åˆå§‹åŒ–æ¨¡å—
æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
1. ollama: æœ¬åœ° Ollama æœåŠ¡
2. custom: æ‰€æœ‰ç¬¬ä¸‰æ–¹ APIï¼ˆOpenAIã€OpenRouterã€DeepSeek ç­‰ï¼‰
"""
from llama_index.core import Settings
from llama_index.llms.ollama import Ollama
from llama_index.embeddings.ollama import OllamaEmbedding
from src.core.custom_embedding import OpenRouterEmbedding
from llama_index.core.postprocessor import SentenceTransformerRerank
from config.settings import *
from src.core.logger import log, error, warn
from src.core.custom_reranker import OllamaReranker, APIReranker, NoReranker
from src.core.custom_llm import GenericOpenAILLM


def init_global_models():
    """
    åˆå§‹åŒ–å…¨å±€æ¨¡å‹é…ç½®
    è¿™æ˜¯æ•´ä¸ª RAG ç³»ç»Ÿçš„å…¥å£å‡½æ•°ï¼Œè´Ÿè´£åˆå§‹åŒ–ï¼š
    - LLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰
    - Embeddingï¼ˆæ–‡æœ¬å‘é‡åŒ–æ¨¡å‹ï¼‰
    - Rerankerï¼ˆé‡æ’åºæ¨¡å‹ï¼‰
    """
    try:
        log("=" * 60)
        log(f"ğŸš€ åˆå§‹åŒ–æ¨¡å‹ Provider: {PROVIDER.name.upper()}")
        log("=" * 60)

        # 1. åˆå§‹åŒ– LLM
        _init_llm()

        # 2. åˆå§‹åŒ– Embedding
        _init_embedding()

        # 3. åˆå§‹åŒ– Reranker
        _init_reranker()

        log("=" * 60)
        log("âœ… å…¨å±€æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        log("=" * 60)

    except Exception as e:
        error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        raise


def _init_llm():
    """
    åˆå§‹åŒ– LLM æ¨¡å‹

    æ ¹æ® PROVIDER é…ç½®é€‰æ‹©ï¼š
    - ollama: æœ¬åœ° Ollama æœåŠ¡
    - custom: ç¬¬ä¸‰æ–¹ API æœåŠ¡
    """
    try:
        if PROVIDER == Provider.OLLAMA:
            # ==================== Ollama æœ¬åœ°æ¨¡å‹ ====================
            Settings.llm = Ollama(
                model=OLLAMA_LLM_MODEL,
                base_url=OLLAMA_BASE_URL,
                request_timeout=360
            )
            log(f"ğŸ“ LLM: Ollama")
            log(f"   â”œâ”€ æ¨¡å‹: {OLLAMA_LLM_MODEL}")
            log(f"   â””â”€ åœ°å€: {OLLAMA_BASE_URL}")

        elif PROVIDER == Provider.CUSTOM:
            # ==================== è‡ªå®šä¹‰ API =========================
            # éªŒè¯å¿…è¦å‚æ•°
            if not CUSTOM_API_KEY or not CUSTOM_BASE_URL or not CUSTOM_LLM_MODEL:
                error("âŒ CUSTOM æ¨¡å¼éœ€è¦è®¾ç½®ä»¥ä¸‹å‚æ•°:")
                error("   - CUSTOM_API_KEY")
                error("   - CUSTOM_BASE_URL")
                error("   - CUSTOM_LLM_MODEL")
                raise ValueError("CUSTOM æ¨¡å¼é…ç½®ä¸å®Œæ•´")

            # ä½¿ç”¨è‡ªå®šä¹‰LLMå°è£…
            Settings.llm = GenericOpenAILLM(
                model=CUSTOM_LLM_MODEL,
                api_key=CUSTOM_API_KEY,
                api_base=CUSTOM_BASE_URL,
                context_window=CUSTOM_CONTEXT_WINDOW,
                max_tokens=CUSTOM_MAX_TOKENS
            )
            log(f"ğŸ“ LLM: è‡ªå®šä¹‰ API")
            log(f"   â”œâ”€ æ¨¡å‹: {CUSTOM_LLM_MODEL}")
            log(f"   â”œâ”€ åœ°å€: {CUSTOM_BASE_URL}")
            log(f"   â”œâ”€ ä¸Šä¸‹æ–‡: {CUSTOM_CONTEXT_WINDOW}")
            log(f"   â””â”€ æœ€å¤§Token: {CUSTOM_MAX_TOKENS}")

        else:
            raise ValueError(f"âŒ æœªçŸ¥çš„ Provider: {PROVIDER}")

    except Exception as e:
        error(f"âŒ LLM åˆå§‹åŒ–å¤±è´¥: {e}")
        raise


def _init_embedding():
    """
    åˆå§‹åŒ– Embedding æ¨¡å‹

    æ ¹æ®é…ç½®é€‰æ‹©ï¼š
    - Ollama Embeddingï¼ˆæœ¬åœ°ï¼Œå…è´¹ï¼‰
    - ç¬¬ä¸‰æ–¹ API Embeddingï¼ˆå¯èƒ½éœ€è¦ä»˜è´¹ï¼‰
    æ³¨æ„ï¼šå¾ˆå¤šç¬¬ä¸‰æ–¹ API ä¸æ”¯æŒ Embeddingï¼Œæ¨èä½¿ç”¨æœ¬åœ° Ollama
    """
    try:
        if PROVIDER == Provider.OLLAMA or USE_OLLAMA_EMBEDDING:
            # ==================== Ollama Embedding ====================
            # ä¸¤ç§æƒ…å†µä¼šä½¿ç”¨ Ollamaï¼š
            # 1. Provider æœ¬èº«å°±æ˜¯ ollama
            # 2. å¼ºåˆ¶è®¾ç½® USE_OLLAMA_EMBEDDING=trueï¼ˆæ··åˆæ¨¡å¼ï¼‰

            Settings.embed_model = OllamaEmbedding(
                model_name=OLLAMA_EMBEDDING_MODEL,
                base_url=OLLAMA_BASE_URL
            )

            if USE_OLLAMA_EMBEDDING and PROVIDER == Provider.CUSTOM: # åˆ¤æ–­æ˜¯ä¸æ˜¯æ··åˆæ¨¡å¼
                log(f"ğŸ”¢ Embedding: Ollamaï¼ˆæ··åˆæ¨¡å¼ï¼‰")
                log(f"   â„¹ï¸LLM ç”¨ç¬¬ä¸‰æ–¹ APIï¼ŒEmbedding ç”¨æœ¬åœ° Ollama")
            else:
                log(f"ğŸ”¢ Embedding: Ollama")

            log(f"   â”œâ”€ æ¨¡å‹: {OLLAMA_EMBEDDING_MODEL}")
            log(f"   â””â”€ åœ°å€: {OLLAMA_BASE_URL}")

        elif PROVIDER == Provider.CUSTOM:
            # ==================== ç¬¬ä¸‰æ–¹ API Embedding ====================
            # åªåœ¨æ˜ç¡®ä¸ä½¿ç”¨ Ollama æ—¶æ‰ä¼šèµ°åˆ°è¿™é‡Œ
            if not CUSTOM_EMBEDDING_MODEL:
                warn("âš ï¸æœªè®¾ç½® CUSTOM_EMBEDDING_MODEL")
                Settings.embed_model = None
            else:
                embedding_model = CUSTOM_EMBEDDING_MODEL

            warn("âš ï¸æ³¨æ„ï¼šå¾ˆå¤šç¬¬ä¸‰æ–¹ API ä¸æ”¯æŒ Embedding")
            warn("âš ï¸å¦‚é‡åˆ°é”™è¯¯ï¼Œè¯·è®¾ç½® USE_OLLAMA_EMBEDDING=true")

            Settings.embed_model = OpenRouterEmbedding(
                model=CUSTOM_EMBEDDING_MODEL,
                api_key=CUSTOM_API_KEY,
                api_base=CUSTOM_BASE_URL
            )
            log(f"ğŸ”¢ Embedding: è‡ªå®šä¹‰ API")
            log(f"   â”œâ”€ æ¨¡å‹: {embedding_model}")
            log(f"   â””â”€ åœ°å€: {CUSTOM_BASE_URL}")

        else:
            raise ValueError(f"âŒ æœªçŸ¥çš„ Provider: {PROVIDER}")

    except Exception as e:
        error(f"âŒ Embedding åˆå§‹åŒ–å¤±è´¥: {e}")
        raise


def _init_reranker():
    """
    åˆå§‹åŒ– Reranker æ¨¡å‹

    Reranker ç”¨äºå¯¹æ£€ç´¢ç»“æœè¿›è¡ŒäºŒæ¬¡æ’åºï¼Œæé«˜ç²¾åº¦

    æ”¯æŒå››ç§æ¨¡å¼ï¼š
    - none: ä¸ä½¿ç”¨ Rerankerï¼ˆæœ€å¿«ï¼Œç²¾åº¦ä¸€èˆ¬ï¼‰
    - local: æœ¬åœ° Sentence Transformer æ¨¡å‹ï¼ˆç²¾åº¦é«˜ï¼Œéœ€è¦ä¸‹è½½æ¨¡å‹ï¼‰
    - ollama: ä½¿ç”¨ Ollama æ¨¡æ‹Ÿ Rerankerï¼ˆå…¼å®¹æ€§å¥½ï¼‰
    - api: ä½¿ç”¨ API æœåŠ¡ï¼ˆéœ€è¦ä»˜è´¹ï¼‰
    """
    try:
        if RERANKER_TYPE == RerankerType.NONE:
            # ==================== ä¸ä½¿ç”¨ Reranker ====================
            Settings.node_postprocessors = [NoReranker(top_n=FINAL_TOP_K)]
            log(f"ğŸ¯ Reranker: ä¸ä½¿ç”¨ï¼ˆç›´æ¥è¿”å› Top {FINAL_TOP_K}ï¼‰")

        elif RERANKER_TYPE == RerankerType.LOCAL:
            # ==================== æœ¬åœ° Reranker ====================
            # è®¾ç½®æ¨¡å‹ç¼“å­˜ç›®å½•
            os.environ['SENTENCE_TRANSFORMERS_HOME'] = RERANKER_CACHE

            Settings.node_postprocessors = [
                SentenceTransformerRerank(
                    top_n=FINAL_TOP_K,
                    model=RERANKER_MODEL
                )
            ]
            log(f"ğŸ¯ Reranker: æœ¬åœ°æ¨¡å‹")
            log(f"   â”œâ”€ æ¨¡å‹: {RERANKER_MODEL}")
            log(f"   â”œâ”€ Top-N: {FINAL_TOP_K}")
            log(f"   â””â”€ ç¼“å­˜: {RERANKER_CACHE}")

        elif RERANKER_TYPE == RerankerType.OLLAMA:
            # ==================== Ollama Reranker ====================
            Settings.node_postprocessors = [
                OllamaReranker(
                    model=OLLAMA_RERANKER_MODEL,
                    base_url=OLLAMA_BASE_URL,
                    top_n=FINAL_TOP_K
                )
            ]
            log(f"ğŸ¯ Reranker: Ollama")
            log(f"   â”œâ”€ æ¨¡å‹: {OLLAMA_RERANKER_MODEL}")
            log(f"   â”œâ”€ åœ°å€: {OLLAMA_BASE_URL}")
            log(f"   â””â”€ Top-N: {FINAL_TOP_K}")

        elif RERANKER_TYPE == RerankerType.API:
            # ==================== API Reranker ====================
            api_key = RERANKER_API_KEY or CUSTOM_API_KEY

            if not api_key:
                warn("âš ï¸  Reranker API Key æœªè®¾ç½®")

            Settings.node_postprocessors = [
                APIReranker(
                    model=RERANKER_MODEL,
                    api_key=api_key,
                    api_base=RERANKER_API_BASE,
                    top_n=FINAL_TOP_K
                )
            ]
            log(f"ğŸ¯ Reranker: API")
            log(f"   â”œâ”€ æ¨¡å‹: {RERANKER_MODEL}")
            log(f"   â”œâ”€ åœ°å€: {RERANKER_API_BASE}")
            log(f"   â””â”€ Top-N: {FINAL_TOP_K}")

        else:
            warn(f"âš ï¸  æœªçŸ¥çš„ Reranker ç±»å‹: {RERANKER_TYPE}")
            Settings.node_postprocessors = [NoReranker(top_n=FINAL_TOP_K)]

    except Exception as e:
        error(f"âŒ Reranker åˆå§‹åŒ–å¤±è´¥: {e}")
        warn("âš ï¸  é™çº§åˆ°ä¸ä½¿ç”¨ Reranker")
        Settings.node_postprocessors = [NoReranker(top_n=FINAL_TOP_K)]


def get_current_config() -> dict:
    """
    è·å–å½“å‰é…ç½®ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•å’Œç›‘æ§ï¼‰

    Returns:
        dict: å½“å‰é…ç½®çš„å­—å…¸
    """
    config = {
        "provider": PROVIDER.name,
        "llm_model": OLLAMA_LLM_MODEL if PROVIDER == Provider.OLLAMA else CUSTOM_LLM_MODEL,
        "embedding_model": OLLAMA_EMBEDDING_MODEL if (
                PROVIDER == Provider.OLLAMA or USE_OLLAMA_EMBEDDING) else CUSTOM_EMBEDDING_MODEL,
        "use_ollama_embedding": USE_OLLAMA_EMBEDDING,
        "reranker_type": RERANKER_TYPE.name,
        "reranker_model": RERANKER_MODEL if RERANKER_TYPE != RerankerType.NONE else None,
        "final_top_k": FINAL_TOP_K,
        "chunk_size": CHUNK_SIZE,
        "chunk_overlap": CHUNK_OVERLAP,
    }
    return config


def print_config():
    """
    æ‰“å°å½“å‰é…ç½®ï¼ˆç”¨äºè°ƒè¯•ï¼‰

    åœ¨å¯åŠ¨æ—¶è°ƒç”¨æ­¤å‡½æ•°å¯ä»¥æŸ¥çœ‹å®Œæ•´çš„é…ç½®ä¿¡æ¯
    """
    config = get_current_config()
    log("\n" + "=" * 60)
    log("ğŸ“‹ å½“å‰é…ç½®")
    log("=" * 60)
    for key, value in config.items():
        log(f"   {key}: {value}")
    log("=" * 60 + "\n")


def validate_config() -> tuple[bool, list[str]]:
    """
    éªŒè¯é…ç½®æ˜¯å¦å®Œæ•´

    Returns:
        tuple: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯åˆ—è¡¨)
    """
    errors = []

    # éªŒè¯ Provider
    if PROVIDER == Provider.CUSTOM:
        if not CUSTOM_API_KEY:
            errors.append("ç¼ºå°‘ CUSTOM_API_KEY")
        if not CUSTOM_BASE_URL:
            errors.append("ç¼ºå°‘ CUSTOM_BASE_URL")
        if not CUSTOM_LLM_MODEL:
            errors.append("ç¼ºå°‘ CUSTOM_LLM_MODEL")

        # å¦‚æœä¸ä½¿ç”¨ Ollama Embeddingï¼Œæ£€æŸ¥ Embedding é…ç½®
        if not USE_OLLAMA_EMBEDDING and not CUSTOM_EMBEDDING_MODEL:
            errors.append("ç¼ºå°‘ CUSTOM_EMBEDDING_MODELï¼ˆæˆ–è®¾ç½® USE_OLLAMA_EMBEDDING=trueï¼‰")

    elif PROVIDER == Provider.OLLAMA:
        if not OLLAMA_BASE_URL:
            errors.append("ç¼ºå°‘ OLLAMA_BASE_URL")
        if not OLLAMA_LLM_MODEL:
            errors.append("ç¼ºå°‘ OLLAMA_LLM_MODEL")
        if not OLLAMA_EMBEDDING_MODEL:
            errors.append("ç¼ºå°‘ OLLAMA_EMBEDDING_MODEL")

    return len(errors) == 0, errors


if __name__ != "__main__":
    is_valid, errors = validate_config()
    if not is_valid:
        warn("âš ï¸  é…ç½®éªŒè¯å¤±è´¥:")
        for err in errors:
            warn(f"   - {err}")
