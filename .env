# ============================================================
# Hardware-RAG 配置文件模板
# ollama 和 custom 两种模式

# ==================== 场景 1: 使用 OpenAI 官方 ====================
PROVIDER=custom
CUSTOM_API_KEY=
CUSTOM_BASE_URL=
CUSTOM_LLM_MODEL=internlm/internlm2_5-7b-chat
CUSTOM_CONTEXT_WINDOW=128000
CUSTOM_MAX_TOKENS=12800

# OpenAI 支持 Embedding API，可以不用 Ollama
USE_OLLAMA_EMBEDDING=false # 不使用ollma
CUSTOM_EMBEDDING_MODEL=Pro/BAAI/bge-m3

RERANKER_TYPE=none

# ==================== 场景 2: 使用 OpenRouter ====================
# PROVIDER=custom
# CUSTOM_API_KEY=sk-or-v1-xxxxxxxxxxxxxxxxxxxxxxxx
# CUSTOM_BASE_URL=https://openrouter.ai/api/v1
# CUSTOM_LLM_MODEL=moonshotai/kimi-k2:free
# CUSTOM_CONTEXT_WINDOW=128000
# CUSTOM_MAX_TOKENS=4096

# # OpenRouter 不支持 Embedding，必须用 Ollama
# USE_OLLAMA_EMBEDDING=true
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text:latest

# RERANKER_TYPE=none


# ==================== 场景 3: 使用 DeepSeek ====================
# PROVIDER=custom
# CUSTOM_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx
# CUSTOM_BASE_URL=https://api.deepseek.com/v1
# CUSTOM_LLM_MODEL=deepseek-chat
# CUSTOM_CONTEXT_WINDOW=64000
# CUSTOM_MAX_TOKENS=4096

# # DeepSeek 不支持 Embedding
# USE_OLLAMA_EMBEDDING=true
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text:latest


# ==================== 场景 4: 使用 Grok (xAI) ====================
# PROVIDER=custom
# CUSTOM_API_KEY=xai-xxxxxxxxxxxxxxxxxxxxxxxx
# CUSTOM_BASE_URL=https://api.x.ai/v1
# CUSTOM_LLM_MODEL=grok-beta
# CUSTOM_CONTEXT_WINDOW=131072
# CUSTOM_MAX_TOKENS=4096

# # Grok 可能不支持 Embedding
# USE_OLLAMA_EMBEDDING=true
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text:latest


# ==================== 场景 5: 使用 Moonshot (Kimi) ====================
# PROVIDER=custom
# CUSTOM_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx
# CUSTOM_BASE_URL=https://api.moonshot.cn/v1
# CUSTOM_LLM_MODEL=moonshot-v1-8k
# CUSTOM_CONTEXT_WINDOW=8000
# CUSTOM_MAX_TOKENS=2000

# # Moonshot 不支持 Embedding
# USE_OLLAMA_EMBEDDING=true
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text:latest


# ==================== 场景 6: 使用 SiliconFlow ====================
# PROVIDER=custom
# CUSTOM_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx
# CUSTOM_BASE_URL=https://api.siliconflow.cn/v1
# CUSTOM_LLM_MODEL=Qwen/Qwen2.5-7B-Instruct
# CUSTOM_CONTEXT_WINDOW=32768
# CUSTOM_MAX_TOKENS=4096

# # SiliconFlow 不支持 Embedding
# USE_OLLAMA_EMBEDDING=true
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text:latest


# ==================== 场景 7: 使用通义千问 ====================
# PROVIDER=custom
# CUSTOM_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx
# CUSTOM_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# CUSTOM_LLM_MODEL=qwen-plus
# CUSTOM_CONTEXT_WINDOW=32000
# CUSTOM_MAX_TOKENS=2000

# # 通义千问支持 Embedding
# USE_OLLAMA_EMBEDDING=false
# CUSTOM_EMBEDDING_MODEL=text-embedding-v2


# ==================== 场景 8: 纯本地 Ollama（免费）====================
# PROVIDER=ollama
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_LLM_MODEL=qwen2.5:7b
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text:latest
# RERANKER_TYPE=none


# ==================== 场景 9: 混合模式（推荐省钱方案）====================
# LLM 用付费 API（高质量），Embedding 用本地 Ollama（免费）
# PROVIDER=custom
# CUSTOM_API_KEY=sk-or-v1-xxxxxxxxxxxxxxxxxxxxxxxx
# CUSTOM_BASE_URL=https://openrouter.ai/api/v1
# CUSTOM_LLM_MODEL=anthropic/claude-3.5-sonnet

# # Embedding 用本地 Ollama（免费）
# USE_OLLAMA_EMBEDDING=true
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text:latest


# ==================== 高级配置（可选）====================
# RAG 参数
# CHUNK_SIZE=512
# CHUNK_OVERLAP=50
# VECTOR_TOP_K=20
# BM25_TOP_K=20
# FINAL_TOP_K=5
# RRF_K=60

# Reranker 配置
# RERANKER_TYPE=local
# RERANKER_MODEL=BAAI/bge-reranker-v2-m3